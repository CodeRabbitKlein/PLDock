下面是我建议的**下一步行动**（按“你马上要改哪些文件/函数、怎么做、做完如何验证”给到可执行细节）。我默认你要走 **MVP 路线：先把监督闭合（None 类 + 候选边 + 负采样）→ 接入一个 NCI 分类头 → 先做 rerank 验证收益**；这样最快能跑通并得到定量反馈。

---

## 0) 下一步的目标与验收标准

### 目标（本轮最关键）

把 `QA.txt` 里“(\hat M \in R^{N_{lig}\times N_{prot}\times 7})”的设想变成**闭合且可训练**的监督：

* 构造候选边集合 (E_{cand})（lig atom → prot residue）
* 为每条候选边打 **8 类标签**：`0=None, 1..7=7种NCI`
* 对正例边附带最小几何标签（先只做 `distance`，角度/offset 可放到下一轮）

### 验收（你要跑的 sanity check）

对任意一个复合物样本：

* `num_pos_edges > 0`（有 PLIP 正例）
* `num_cand_edges` 在合理范围（例如 2k–20k，取决于 cutoff 与采样）
* `pos_ratio = num_pos / num_cand` 大致在 0.1%–5%（正常稀疏）
* `None` 标签占多数（否则候选边或负采样逻辑错误）
* 训练一个 epoch 后，`L_type` 能稳定下降（不 NaN，不爆炸）

---

## 1) 数据预处理：新增一个“候选边 + 8类标签”的离线产物

### 1.1 你要新增/改动的输出字段（建议存到 `.pt` 或 `.npz`）

对每个复合物样本保存：

* `lig_pos` : `(N_lig, 3)`
* `res_pos` : `(N_prot, 3)`（残基代表点，先用 CA；后续再换功能点）
* `cand_edge_index` : `(2, E)`，第一行是 lig atom idx，第二行是 residue idx
* `cand_edge_y_type` : `(E,)`，取值 0到7
* `pos_edge_list_sparse`（可选）：保存真实 PLIP 正例稀疏表，方便 debug
* `edge_y_dist` : `(E,)`，仅对正例有意义（None 可置 0 并用 mask）

> 这一套字段会让训练完全闭合：模型看到所有候选边，学会区分 None vs NCI。

### 1.2 候选边构造（你现在就该落这个）

给定 `lig_pos` 与 `res_pos`：

* 用半径邻域：`cutoff = 10.0Å`（MVP 固定即可）
* 实现方式：

  * `KDTree` 
  * 得到所有满足 `dist < cutoff` 的 pair 作为 `E_cand`

#### 负采样（必须加，否则 E_cand 太大）

你要在构造候选边后做一层采样：

* 对每个 ligand atom：

  * 保留全部正例边
  * 从 None 边里随机采样 `neg_per_pos * num_pos_i + neg_min`
  * 例如：`neg_per_pos=20, neg_min=10, neg_max=200`（经验上好用）
    这样每个 lig atom 都有负样本，且规模可控。

---

## 2) PLIP 正例映射：把正例打到候选边上（避免全连接监督）

### 2.1 建立 “正例字典”

你从 PLIP 解析得到的正例边要统一成：

* `pos_map[(lig_atom_idx, prot_res_idx)] = type_id (1..7)`
* `pos_dist[(lig_atom_idx, prot_res_idx)] = distance`

注意事项（防错）：

* 如果 PLIP 给的是环中心/多原子（π类）：MVP 先按“分配给环上全部原子”的策略，变成多条正例键值对。
* 映射失败（找不到 lig atom / residue）：直接丢弃该 interaction 并计数；若丢弃比例过高（比如 >30%），把该复合物标为 bad sample 直接跳过训练，避免脏标签。

### 2.2 给候选边打标签

遍历 `cand_edge_index` 的每条边 `(i,j)`：

* 若 `(i,j)` 在 `pos_map`：`y_type = pos_map[(i,j)]`，`y_dist = pos_dist[(i,j)]`
* 否则：`y_type = 0`（None），`y_dist = 0`

并生成：

* `pos_mask = (y_type > 0)` 用于回归项（下一轮会用）

---

## 3) 数据加载器与 PyG 数据对象：把训练需要的张量接好

当前的 `HeteroData` 里已经有：

* `ligand.x`, `ligand.pos`
* `receptor.x`（目前是 zeros，需要补 residue type embedding）
* `('ligand','interacts','receptor').edge_index`（你现在多半只存正例）

下一步你要做的具体变更是：

### 3.1 不再用 edge_index 表示“正例”，而是表示“候选边”

* `edge_index := cand_edge_index`
* 新增：

  * `edge_type_y := cand_edge_y_type`（训练标签）
  * `edge_dist_y := cand_edge_y_dist`（先存，训练可先不用）

> 这是最关键的结构变化：你的分类头将对 **所有候选边** 输出 8 类概率。

### 3.2 receptor.x 从全 0 改成最小有效特征

MVP 至少加两类：

* `residue_aa_type`（采用代码中原有定义）
* `is_pocket`（bool：采用代码中原有定义）

这两个特征能显著减少“蛋白节点不可辨识”导致的训练不收敛问题。

---

## 4) 模型改造：新增一个 NCI 分类 head（只做 type，不做 geom）

### 4.1 head 的输入来自哪里（最小侵入）

不改变 DiffDock 主干结构，你只需要在“lig-prot cross edges”那里取一个 edge 表示 `h_ij`：

* `h_ij = concat(h_lig[i], h_prot[j], rbf(dist_ij))`
* 经过 2 层 MLP 输出 `logits_ij`（8 维）

### 4.2 损失函数（本轮只做这一条）

* `L_type = FocalCE(logits, y_type)` 或 class-balanced CE
* 总损失：`L = L_diff + λ * L_type`（λ 先取 1.0；如果对主任务干扰大再调）

下面我把这一段“只加一个 NCI 分类损失”的训练逻辑讲清楚：你现在是在 DiffDock 的主训练目标之外，再引入一个辅助任务（auxiliary task）来教模型学会预测相互作用类型。关键点在于：这个辅助任务要解决类别极不平衡，并且不能把主任务（对接/去噪）训练带崩。因此我建议用 Focal CE 并用一个系数 λ 控制它在总损失里的影响。
---

## 1) 先把符号讲清楚：logits、y_type、L_type 分别是什么

你在构造候选边集合 (E_{cand}) 后，每条候选边是一对 ((i,j))：

* (i)：配体原子 index
* (j)：蛋白残基 index

### y_type：监督标签（8 类）

对每条候选边 ((i,j))，你给一个整数标签：

* (y_{ij} = 0)：None（没有任何相互作用）
* (y_{ij} \in {1..7})：7 种 NCI 类型之一（hydrophobic / hbond / saltbridge / pistacking / pication / halogen / metal）

所以 `y_type` 的 shape 是：

* `y_type`: `(E,)`，E = 候选边数

### logits：模型输出（未归一化分数）

你给每条候选边输出一个 8 维向量：

* `logits_ij`: `(8,)`

把所有边拼起来：

* `logits`: `(E, 8)`

通过 softmax 得到概率：
p_{ij}(c)=\mathrm{softmax}(\text{logits}_{ij})_c,\quad c=0..7


### L_type：分类损失（让预测贴近 y_type）

`L_type` 就是把这些概率和真实标签对齐的损失函数，最常见是交叉熵（CE）。但你的数据里 `None` 会占绝大多数（稀疏相互作用），这会导致普通 CE 的训练出现两个典型问题：

1. 模型学会“全预测 None”，CE 也能很低（因为 99% 都是 None）
2. 正例（7 类 NCI）梯度太弱，模型学不到你关心的交互规律

所以才需要 FocalCE来“扶正”正例的梯度。

---
## 2)辅助任务损失 ：FocalCE 
可以。你在这个辅助任务里直接用 **Focal Cross-Entropy（多分类版）**是合理且常见的选择，尤其是你这里 `None` 边占绝大多数、而正类稀疏且更“难”的场景。

下面给你一个**可直接落地到 PyTorch 训练循环**的版本（含公式、超参建议、实现要点、与总损失的组合方式）。

---

## 1) 你要用的多分类 Focal CE 形式

对每条候选边 (e)（对应一对 ((i,j))）：

* 模型输出：`logits_e`，shape `(C,)`，这里 (C=8)
* 真实标签：`y_e`，取值 `0..7`
* 概率：(p_e = \mathrm{softmax}(\text{logits}_e))
* 取出真类概率：(p_{t} = p_e[y_e])

**多分类 Focal CE（常用写法）**：
[
\mathcal{L}*e = - \alpha*{y_e}, (1 - p_t)^{\gamma}, \log(p_t)
]

* (\gamma \ge 0) 控制“聚焦难样本”程度：(\gamma) 越大，越忽略 easy 样本（比如 easy None）
* (\alpha_{y}) 是类别权重（可选但我强烈建议用）：让稀有正类更“被看见”，同时把 `None` 的权重压低

最后对所有边取均值/求和得到 (L_{type})。

---

## 2) 推荐超参（针对你这个 8 类：None + 7 NCI）

### γ（最重要）

* **推荐默认：`gamma = 2.0`**

### α（类别权重，建议一定要有）
要做到：**None 的 α 小一些，正类 α 大一些**。

* `alpha_none = 0.25`
* `alpha_pos = 1.0`（正类 1..7 都用 1.0）

这会明显削弱 None 的主导性。
---

## 3) PyTorch 实现（多分类 Focal CE，数值稳定版）

下面这个实现是工程上最常用、也最稳的写法：用 `log_softmax` 保持数值稳定。

```python
import torch
import torch.nn.functional as F

def focal_ce_multiclass(
    logits: torch.Tensor,        # (E, C)
    targets: torch.Tensor,       # (E,) int64 in [0, C-1]
    alpha: torch.Tensor = None,  # (C,) or None
    gamma: float = 2.0,
    reduction: str = "mean",
) -> torch.Tensor:
    """
    Multi-class focal cross entropy.
    """
    # log_probs: (E, C)
    log_probs = F.log_softmax(logits, dim=-1)
    # probs: (E, C)
    probs = log_probs.exp()

    # gather true class prob and log prob: (E,)
    targets = targets.long()
    pt = probs.gather(dim=-1, index=targets.unsqueeze(-1)).squeeze(-1)
    log_pt = log_probs.gather(dim=-1, index=targets.unsqueeze(-1)).squeeze(-1)

    # focal factor: (E,)
    focal_factor = (1.0 - pt).clamp(min=0.0, max=1.0) ** gamma

    # alpha factor: (E,)
    if alpha is not None:
        # alpha: (C,)
        at = alpha.gather(dim=0, index=targets)
        loss = -at * focal_factor * log_pt
    else:
        loss = -focal_factor * log_pt

    if reduction == "mean":
        return loss.mean()
    elif reduction == "sum":
        return loss.sum()
    elif reduction == "none":
        return loss
    else:
        raise ValueError(f"Unknown reduction: {reduction}")
```

### α 的构造例子（方案 A）

```python
C = 8
alpha = torch.ones(C, device=logits.device)
alpha[0] = 0.25  # None
gamma = 2.0
L_type = focal_ce_multiclass(logits, y_type, alpha=alpha, gamma=gamma)
```

---

## 4) 你总损失的组合方式（和 DiffDock 主损失并行）

你的总损失仍然是：L = L_{diff} + \lambda , L_{type}


对应代码：

```python
L = L_diff + lam * L_type
```
* 先设 `lam = 1.0`
---

## 5) 必须做的两个训练监控（否则很容易“看着 loss 降但学废了”）

在每个 batch 里额外打印两件事（成本很低，收益很大）：

1. **正类召回趋势（粗略即可）**

* 取 `pred = argmax(logits)`，算：

  * `pos_recall = (# y>0 且 pred>0) / (# y>0)`
  * 以及 `none_acc = (# y==0 且 pred==0) / (# y==0)`
* 希望看到：`pos_recall` 从接近 0 逐步上升，而 `none_acc` 仍然较高

2. **top-K 正类边的置信度**

* 对每个样本，取 `p_non_none = 1 - p(None)`
* 看 top-50 的平均 `p_non_none` 是否上升
  这直接关系到你后续 rerank/guidance 是否能闭环。

---

## 6) 常见坑与避免方式（你很可能会遇到）

* **坑 1：没有负采样 / 候选边过多**
  Focal 也救不了显存和训练速度。务必控制 `E` 的规模。

* **坑 2：α 设得过激（尤其用 1/freq）**
  会导致少数类梯度过大、训练不稳定。优先用 `1/sqrt(freq)` 或方案 A。

* **坑 3：只看 loss，不看 pos_recall**
  你会误以为收敛了，但其实模型仍然在预测 None。

---

## 3) 总损失为什么是 L = L_diff + λ * L_type（λ 的意义是什么）

你现在的训练有两个目标：

1. **主任务（DiffDock）**：去噪/score matching 等扩散训练目标
   记为 (L_{diff})。它直接决定 docking 的 RMSD、成功率等。

2. **辅助任务（NCI 分类）**：让模型学会预测交互类型
   记为 (L_{type})。它帮助模型学习“什么几何/化学模式对应什么相互作用”，从而潜在提升主任务，且推理时可用于 rerank/guidance。

如果你把两个损失直接相加：

L = L_{diff} + L_{type}

会有一个问题：**两者的尺度（数值量级）不一定一致**，而且训练初期辅助任务可能很难，梯度很大，会把主任务带偏。

因此引入 λ：
L = L_{diff} + \lambda L_{type}

初始 λ=1。


## 5) 按这个顺序做：

1. **先做负采样**（比换损失函数更关键）

2. **先用 Weighted CE** 跑通（实现最简单）

   * 例如：`w_none = 1`, 所有正类统一 `w_pos = 10` 起步
   * 看正类 recall 是否从 0 变得可用

3. 如果仍然出现“全 None”或正类学得很慢，再切换到 **FocalCE (γ=2)**

   * 同时用 α 对正类略加权（例如 α_pos=1, α_none=0.25 或按频率设）

4. λ：先用 1.0；如果主任务被干扰，改成 0.2 或 0.5；如果 NCI 学不到，改到 2.0。

---
---

## 5) 推理与验证：先做 rerank（不做 guidance）
核心思想是：你先不把 NCI 能量项塞进扩散采样过程（那会引入不稳定和额外调参），而是把它当成一个后验评估器/重打分器，对 DiffDock 生成的多个候选 pose 重新排序，从而验证“辅助任务是否真的学到了有用的相互作用规律”。下一步你要加一个 “NCI一致性打分”：

## Rerank 的目标：不改采样，只改“排序规则”

DiffDock 的推理管线是：

1. 扩散采样生成 N 个 pose（默认 `samples_per_complex=10`）
2. 用置信度模型（confidence model）给每个 pose 打分并排序
3. 按排序把 pose 写成 `rank{...}_confidence{...}.sdf`

“先做 rerank”的意思是：**保留 1) 采样完全不动**，在 2) 与 3) 之间加一个额外分数 `score_nci`，用它来**重新排序**这 N 个 pose，然后再保存。

最终排序分数：score_{final}(k) = score_{conf}(k) + \alpha \cdot score_{nci}(k)


* `score_conf(k)`：DiffDock 原来的置信度分数（你现在已经有）
* `score_nci(k)`：由你的 NCI 辅助头（FocalCE 训练得到）在推理时对该 pose 的“相互作用一致性评分”
* α：一个很小的融合系数（建议从 0.05 或 0.1 起步）

---

## 2) 你手头数据如何用于 rerank：坐标系一致性是第一要点

当前项目保存 pose 的方式是（全局坐标）：

```python
ligand_pos_global = complex_graph['ligand'].pos + orig_complex_graph.original_center
```

那么你用于构造候选边、算距离、喂给 NCI head 的 receptor 残基坐标也必须在同一坐标系下。通常 `complex_graph['receptor'].pos` 也在“以 original_center 为中心的局部坐标系”里，因此你要同样平移：

```python
receptor_pos_global = complex_graph['receptor'].pos + orig_complex_graph.original_center
``` 只要两边都加同一个 `original_center`，你做半径邻域（8Å cutoff）和边特征计算就一致了。


---

## Rerank 的核心：如何从一个 pose 得到 `score_nci`

### 构造候选边集合 (E_{cand})

因为 receptor 是残基级，你的候选边是：

ligand atom (i) → receptor residue (j)

候选边构造（MVP 推荐）：

cutoff = 10.0 Å（与 pocket 尺度一致）
做法：计算所有 ligand atoms 到所有 residues 的距离矩阵 `D`，取 `D < cutoff` 的 (i, j)

PyTorch 最直接版本（N=10、残基数几百、配体原子几十，成本很低）：

```python
# lig_pos: (N_lig, 3), rec_pos: (N_res, 3)
D = torch.cdist(lig_pos, rec_pos)              # (N_lig, N_res)
mask = D < cutoff
i_idx, j_idx = torch.where(mask)               # (E,)
edge_index = torch.stack([i_idx, j_idx], dim=0)  # (2, E)
edge_dist  = D[i_idx, j_idx]                   # (E,)
```


### 3.2 用 NCI head 得到每条边的 8 类概率

你要的 NCI head 在推理时输出：

* `logits_ij`：shape `(E, 8)`（8类：None + 7 类 NCI）

然后：

```python
probs = softmax(logits, dim=-1)      # (E, 8)
conf_edge = probs[:, 1:].max(dim=-1).values   # (E,)  非None最大概率
```

### 3.3 取 top-K 高置信边，把它们聚合成 pose 分数

这是 rerank 的关键：你不能把所有 E 条边都加总，否则分数会被噪声淹没、也会偏向“大配体/接触多”的 pose。做法：

* K 固定，例如 K=50（或 K=30）
* 取 `conf_edge` 的 top-K
* 用对数平均作为 `score_nci`

推荐的 **尺度稳定**版本：score_{nci}=\frac{1}{K}\sum_{e\in topK}\log(\epsilon+conf_e)

实现：

```python
K = min(K, conf_edge.numel())
top_conf = torch.topk(conf_edge, K).values
score_nci = torch.log(top_conf + 1e-6).mean()
```

这样 `score_nci`：

* 会奖励“存在一批强相互作用模式”的 pose
* 不会因为 pose 接触边数更多而无脑变大（因为固定 top-K 且取 mean）

---

## 4) 你应当把 rerank 插到 inference.py 的哪里

你描述的 `inference.py:344-361` 逻辑大概率是：

* 生成 `data_list`（每个元素是一个 pose 的图）
* 计算 confidence scores 并排序
* 保存 SDF（按排序后的顺序逐个写）

你要做的是：**在“confidence 排序”之后、“写 SDF”之前**插入：

1. 对排序后的每个 pose 计算 `score_nci(k)`
2. 计算 `score_final(k)` 并重新排序
3. 用新排序写 SDF（同时把文件名里写上 confidence 与 nci 分数，便于你排查）

---

## 5) 最关键的工程选择：NCI head 应该挂在哪个模型上？

我建议你把 NCI head 挂在 confidence model 上，原因：

confidence model 本来就要对每个 pose 前向一次（你已经付出成本）
你只需让它额外输出 `nci_logits`，几乎不增加推理复杂度
不需要再调用 diffusion/score 模型或处理 time step

### 推荐接口改造

把 confidence model forward 改成返回：

* `conf_score`（原来就有）
* `nci_logits`（新增，edge-level logits）

即：

```python
conf_score, nci_logits = confidence_model(complex_graph, return_nci=True)
```
---

## 6) 可以参考的 rerank 伪代码

假设你已经有：

* `data_list`: list[complex_graph]，长度 N（每个 pose 一个 graph）
* `orig_center = orig_complex_graph.original_center`
* `confidence_scores`: shape (N,)

你可以这样做：

```python
alpha = 0.1
cutoff = 8.0
K = 50

nci_scores = []
for complex_graph in data_list:
    lig_pos = complex_graph['ligand'].pos  # (N_lig, 3) 局部坐标也可以
    rec_pos = complex_graph['receptor'].pos  # (N_res, 3)

    # 若你用全局坐标保存，就两边都 + orig_center；若局部就都不加
    # lig_pos = lig_pos + orig_center
    # rec_pos = rec_pos + orig_center

    edge_index, edge_dist = build_radius_edges(lig_pos, rec_pos, cutoff)

    logits = nci_head_forward(complex_graph, edge_index, edge_dist)  # (E, 8)
    probs = torch.softmax(logits, dim=-1)
    conf_edge = probs[:, 1:].max(dim=-1).values  # (E,)

    if conf_edge.numel() == 0:
        score_nci = torch.tensor(-20.0, device=conf_edge.device)  # 极端情况兜底
    else:
        top_conf = torch.topk(conf_edge, k=min(K, conf_edge.numel())).values
        score_nci = torch.log(top_conf + 1e-6).mean()

    nci_scores.append(score_nci)

nci_scores = torch.stack(nci_scores)               # (N,)
final_scores = confidence_scores + alpha * nci_scores
rerank_idx = torch.argsort(final_scores, descending=True)

data_list = [data_list[i] for i in rerank_idx]
confidence_scores = confidence_scores[rerank_idx]
nci_scores = nci_scores[rerank_idx]
```

保存时文件名建议改为：

* `rank{r}_conf{conf:.2f}_nci{nci:.3f}.sdf`

这样你一眼就能看到 rerank 是否在起作用。

---

## 7) 验证 rerank 是否“有效”，而不是随机扰动排序

在有晶体真值的验证集上（PDBBind split）跑两组：

1. Baseline：按原 confidence 排序取 Top-1 / Top-5
2. Rerank：按 `conf + α*nci` 排序取 Top-1 / Top-5

对比指标：

* Top-1 RMSD（越低越好）
* Success@2Å（Top-1、Top-5）
* 如果 rerank 只在 Top-5 提升，说明 NCI 分数有用但力度不够，可调 α 或改 top-K 策略

---

## 9) 你下一步我建议你做的“最小改动”路线

为了最稳、最少改代码：

1. **先不改 diffusion 模型**
2. 在 inference 中：

   * 用现有 confidence 排序得到前 N 个 pose
   * 用一个单独的 `nci_head` 模块（哪怕先是简化版 MLP）对每个 pose 输出 edge logits
   * 做 rerank 并保存文件名带上 `nci`


---































## Rerank 的输入输出是什么

### 输入
对每个复合物（protein + ligand），DiffDock 推理一般会生成多个候选构象：
* ( {x^{(1)}, x^{(2)}, \dots, x^{(N)}} )（N 常见 10、20、40）
  每个候选 pose (x^{(k)}) 包含配体 3D 坐标（以及可能的 torsion/rot/trans 表示）。
同时 DiffDock 本身通常还会给一个置信度评分记为： `confidence`
### 输出

你要给每个 pose 再算一个 NCI 一致性分数：

* `score_nci(k)`
  然后把两者融合得到最终排序分数：
* `score_final(k) = score_dd(k) + α * score_nci(k)`（或其他组合方式）
  最后按 `score_final` 排序取 Top-1/Top-5 做评估。



---

### 5.1 对每个 pose 计算 NCI 分数

* 构造该 pose 的 `E_cand`（同训练 cutoff）
* 前向得到 `p(type_ij)`
* 取 top-K 非 None 边（比如 K=50）
* 定义分数：`score_nci = sum_{topK} log p(type_ij)`（或加权和）

##  score_nci(k) 到底怎么计算：从“候选边→概率→top-K→打分”

这是 rerank 的核心闭环。对每个 pose (x^{(k)})：

### Step 1：构造候选边集合 (E_{cand})

和训练时一致：对每个 ligand atom (i)，找 8Å（或 10Å）内的蛋白残基 (j)，形成候选边集合。

* 这一步不需要 PLIP，也不需要任何真值标签
* 你只用当前 pose 的几何关系来构边

### Step 2：跑 NCI head 得到每条边的 logits / 概率

对每条候选边 ((i,j))，模型输出：

* `logits_ij`（8 类）
* 概率 (p_{ij}(c)=softmax(logits_{ij})_c)

你关心的是：

* `p_none = p_ij(0)`
* `p_non_none = 1 - p_none`（这条边“存在某种相互作用”的概率）
* 以及各类型概率 `p(type=t)`（t=1..7）

### Step 3：选择 top-K “最可信的相互作用边”

因为候选边很多（上千上万），你不能全加到分数里，否则分数会被海量噪声淹没。
常用做法：

* 对每条边计算一个“边置信度”：

  * `conf_ij = max_{t=1..7} p_ij(t)`（最可能的相互作用类型的概率）
* 取 top-K（比如 K=50）边：

  * `E_topK = topK(conf_ij)`

这一步的意义：只用模型最确信的少数边来评价该 pose 是否“合理”。

### Step 4：把 top-K 边转换为 pose 的 NCI 分数

一个简单但非常有效的定义是“对数似然和”：

score_{nci}(k) = \sum_{(i,j)\in E_{topK}} \log(\epsilon + \max_{t\ge1} p_{ij}(t))


* 这里 (\epsilon) 是防止 log(0) 的小数，比如 1e-6
* 直觉：如果这个 pose 形成了很多“模型认为很像真实相互作用模式”的边，那么这些边的正类概率会高，log 和就更大


### 5.2 最终排序

* 原 DiffDock score（或 confidence）与 `score_nci` 融合：

  * `score_final = score_diffdock + α * score_nci`
  * α 从小开始（比如 0.1），观察 Top-1/Top-5 RMSD 改善

---

## 6) 我建议你按这个顺序提交改动（避免一次改太多）

1. **离线预处理脚本**：能生成 `cand_edge_index + y_type`
2. **Dataset/Dataloader**：能把这些张量喂进模型
3. **模型 head**：能输出 `logits_type`
4. **训练跑通**：`L_type` 下降且不影响 `L_diff` 的稳定性
5. **rerank 验证**：看 docking 指标是否有收益

---
最后，请你分析当前项目的目录结构（数据类/模型类/训练入口等）把上述行动进一步结合到具体代码进行修改。